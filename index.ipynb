{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Power - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this lesson, we will consider a general-purpose simulation approach to estimating the power of an experimental design. Power analysis is an important aspect of experimental design. It allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. In other words, it allows us to determine the probability of detecting an effect of a given size with a given level of confidence, under sample size constraints. If this probability is unacceptably low, we would be wise to alter or abandon the experiment.\n",
    "\n",
    "The following four factors have an intimate relationship:\n",
    "\n",
    "* Sample size\n",
    "* Effect size\n",
    "* Significance level = P (Type I error) = probability of finding an effect that is not there\n",
    "* **Power = 1 - P (Type II error)** = probability of finding an effect that is there\n",
    "\n",
    "Given any three of these, we can easily determine the fourth.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Describe the concept of “Power” in relation to p-value and effect size for hypothesis testing\n",
    "* Understand and critically evaluate the factors influencing the power of an experiment\n",
    "* Perform Power calculation using SciPy and Python\n",
    "* Demonstrate the impact of sample size on statistical power using simulations\n",
    "* Demonstrate the combined effect of sample size and effect size on statistical power using simulations  \n",
    "\n",
    "## Let's get started!\n",
    "  \n",
    "To start, let's import the necessary libraries required for this simuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "A researcher wants to study how daily protein supplementation in the elderly population will affect baseline liver fat. The study budget will allow enrollment of 24 patients. Half will be randomized to a placebo group and half to the protein supplement treatment group and the trial will be carried out over one month. It is desired to see whether the mean change in percentage of liver fat from baseline to the end of the study differs between the two groups in the study. \n",
    "\n",
    "So we have the null hypothesis \n",
    "\n",
    "**There is no difference between experimental and control means i.e. H0 is equal to H1**\n",
    "\n",
    "And the alternative Hypothesis\n",
    "\n",
    "**There is a difference between experimental and control means i.e. H0 is not equal to H1**\n",
    "\n",
    "The researcher needs to know what power  will be obtained under the sample size restrictions to identify a change in mean percent liver fat of 0.17. Based on past results, a common standard deviation of 0.21 will be used for each treatment group in the power analysis. \n",
    "\n",
    "We will run a simulation with above information to calculate the power expected from the given sample size. From above we have following data to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients in each group\n",
    "sample_size = 12\n",
    "\n",
    "# Control group\n",
    "control_mean = 0\n",
    "control_sd = .21\n",
    "\n",
    "# Experimental group\n",
    "experimental_mean = .17\n",
    "experimental_sd = .21\n",
    "\n",
    "#Set the number of simulations for our test = 1000\n",
    "n_sim = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start running our simulations to run an independance t-test with above data and store the calculated p_value in our `p` array. Perform following tasks.\n",
    "\n",
    "* Initialize a numpy array and fill it with Nan values for storing the results (p_value) of our independance T-test.\n",
    "* For defined number of simulations (i.e. 1000), do the following:\n",
    "\n",
    "    * Generate a random normal variable with control mean and sd\n",
    "    * Generate a random normal variable with experimental mean and sd\n",
    "    * Run and independant t-test using control and experimental data\n",
    "    * Store the p value for each test\n",
    "\n",
    "* Calculate the total number and overall proportion of simulations and where Null hypothesis is rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.495"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducability \n",
    "np.random.seed(10)\n",
    "\n",
    "# Initialize array to store results\n",
    "p = (np.empty(n_sim))\n",
    "p.fill(np.nan)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_sim):\n",
    "    control= np.random.normal(control_mean, control_sd, 12)\n",
    "    experiment= np.random.normal(experimental_mean, experimental_sd, 12)\n",
    "#  Run a for loop for range of values in n_sim\n",
    "    t_test= stats.ttest_ind(control, experiment)\n",
    "    p[i]= t_test[1]\n",
    "\n",
    "\n",
    "# num=0\n",
    "# for i in range(n_sim):\n",
    "#     if .17>experiment[i]:\n",
    "#         num += 1 \n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "# number of null hypothesis rejections\n",
    "num_null_rejects = np.sum(p<0.05)\n",
    "reject_proportion = num_null_rejects/float(n_sim)\n",
    "\n",
    "reject_proportion\n",
    "\n",
    "# 0.495"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results tell us that using 12 participants in each group and with given statistics, the power we obtain is 49% for our test settings. This can be interpreted as follows:\n",
    "\n",
    "> **If a large effect is truly present between control and experimental groups, then the null hypothesis (i.e. no difference with alpha 0.05) would be rejected 49% of times. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample size requirements for a given effect size\n",
    "\n",
    "The researcher conducting this experiment is not satisfied with the results of power calculations shown above, and would like to work out what sample size is required in order to be able to reject the null hypothesis 95% of times that an effect size of 0.17 exists between control and experimental group means. (as compared to 49% with current sample size). \n",
    "\n",
    "To achieve this, we shall move on to a more common scenario, where a design and effect size is decided and we would like to know what sample size is needed to achieve a particular power. This is a straightforward extension of the previous example: we begin with a current sample size and calculate the associated power. We then perform such a calculation repeatedly, each time increasing the sample size, until the power has reached the desired level.\n",
    "\n",
    "Let's define our experimental parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required power 0.95\n",
    "target = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to define the number of simulations and a `current` variable for an iterative comparison with target power defined. We shall start with a sample size of 12 (current) and keep increasing it until the required power is achieved. We shall also increase the number of simulations to 10,000 for a more deterministic output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum sample size to start the simulations \n",
    "sample_size = 12\n",
    "current = 0\n",
    "n_sim = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, perform the following\n",
    "\n",
    "* Initialize an empty array for storing results\n",
    "* initiliaze a list for storing samplesize x power summary\n",
    "* While current power is less than target power\n",
    "    * Generate distributions for control and experimental groups using given statistics (as before)\n",
    "    * Run a t-test and store results\n",
    "    * Calculate current power \n",
    "    * Output current sample size and power calculated for inspection\n",
    "    * Store results: Sample size , power\n",
    "    * increase the sample size by 1 and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "p = (np.empty(n_sim))\n",
    "p.fill(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "target = .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 42 , Calculated Power = 0.958\n"
     ]
    }
   ],
   "source": [
    "while current< target:\n",
    "    data = np.empty([n_sim, sample_size, 2])\n",
    "    data.fill(np.nan)\n",
    "    p = (np.empty(n_sim))\n",
    "    p.fill(np.nan)\n",
    "    data[:,:,0]= np.random.normal(control_mean, control_sd, size = [n_sim,sample_size])\n",
    "    data[:,:,1]= np.random.normal(experimental_mean, experimental_sd, size= [n_sim, sample_size])\n",
    "#  Run a for loop for range of values in n_sim\n",
    "    t_test= stats.ttest_ind(data[:,:,0], data[:,:,1],axis=1)\n",
    "    p= t_test[1]\n",
    "    num_null_rejects = np.sum(p<.05)\n",
    "    power = num_null_rejects/float(n_sim)\n",
    "    current = power\n",
    "    print (\"Number of Samples:\", sample_size,\", Calculated Power =\", current)\n",
    "    power_sample.append([sample_size , current])\n",
    "    sample_size += 1\n",
    "\n",
    "# keep iterating as shown above until desired power is obtained\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 0.958]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[176, 1.0]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot calculated power against sample size to visually inspect the effect of increasing sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a sample size X Power line graph \n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RcParams in module matplotlib object:\n",
      "\n",
      "class RcParams(collections.abc.MutableMapping, builtins.dict)\n",
      " |  A dictionary object including validation\n",
      " |  \n",
      " |  validating functions are defined and associated with rc parameters in\n",
      " |  :mod:`matplotlib.rcsetup`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RcParams\n",
      " |      collections.abc.MutableMapping\n",
      " |      collections.abc.Mapping\n",
      " |      collections.abc.Collection\n",
      " |      collections.abc.Sized\n",
      " |      collections.abc.Iterable\n",
      " |      collections.abc.Container\n",
      " |      builtins.dict\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Yield sorted list of keys.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, key, val)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  copy(self)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  find_all(self, pattern)\n",
      " |      Return the subset of this RcParams dictionary whose keys match,\n",
      " |      using :func:`re.search`, the given ``pattern``.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          Changes to the returned dictionary are *not* propagated to\n",
      " |          the parent RcParams dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  msg_backend_obsolete\n",
      " |      .. deprecated:: 3.0\n",
      " |          The msg_backend_obsolete function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      " |      \n",
      " |      \\\n",
      " |  \n",
      " |  msg_depr\n",
      " |      .. deprecated:: 3.0\n",
      " |          The msg_depr function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      " |      \n",
      " |      \\\n",
      " |  \n",
      " |  msg_depr_ignore\n",
      " |      .. deprecated:: 3.0\n",
      " |          The msg_depr_ignore function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      " |      \n",
      " |      \\\n",
      " |  \n",
      " |  msg_depr_set\n",
      " |      .. deprecated:: 3.0\n",
      " |          The msg_depr_set function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      " |      \n",
      " |      \\\n",
      " |  \n",
      " |  msg_obsolete\n",
      " |      .. deprecated:: 3.0\n",
      " |          The msg_obsolete function was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      " |      \n",
      " |      \\\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'__delitem__'})\n",
      " |  \n",
      " |  validate = {'_internal.classic_mode': <function validate_bool>, 'agg.p...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.MutableMapping:\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |  \n",
      " |  clear(self)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  pop(self, key, default=<object object at 0x7f315780c050>)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      " |  \n",
      " |  popitem(self)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      " |      as a 2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(self, key, default=None)\n",
      " |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      " |  \n",
      " |  update(*args, **kwds)\n",
      " |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      " |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      " |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      " |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  items(self)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(self)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  values(self)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from collections.abc.Mapping:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __reversed__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Collection:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.dict:\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from abc.ABCMeta\n",
      " |      Returns a new dict with keys from iterable and values equal to value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rcParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above output tells us that for our researcher, in order to get the required power (95%) for the observed effect of 0.17 , he would need considerably higher number of patients in each group i.e. 41. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**BONUS EXERCISE: Calculating power across varying sample and effect sizes**\n",
    "\n",
    ">In the previous examples, we have assumed a fixed effect size. However, perhaps we want to investigate how power changes with both effect size and sample size. This is again a straightforward extension of the previous example. \n",
    "\n",
    ">1. Generate samples with sizes ranging from 10 to 50 per group\n",
    "2. Set effect size from less than small (i.e. 0.1) to slightly bigger than large (0.8)\n",
    "3. set number of simulations to 10000\n",
    "4. Use nested For loop i.e. for all chosen effect sizes,for all chosen sample sizes, for all groups (i.e. 2) - run the 2 sample independant test and store power, chosen sample size and effect size\n",
    "5. Visualize your data in a meaningful way to communicate results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, we recieved an understanding around the idea of \"statistical power\" and how sample size, p_value and effect size impact the power of an experiment. We ran a simulation to determine the sample size that would provide a given value of power. In the second simulation, we saw the combined effect of sample size and effect size on the power. We can conclude this lesson with the ideas that a) Statistical power increases as we increase the sample size and b) with a small effect size, we require a large number of samples to achieve required power and vice versa. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
